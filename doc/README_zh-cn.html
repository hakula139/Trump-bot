<!DOCTYPE html><html><head>
      <title>README_zh-cn</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"]}});
        </script>
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
        
      
      
      
      
      
      
      
      
      
      <style>
      pre{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;padding:1em;margin:.5em 0;overflow:auto;line-height:1.5;tab-size:4;hyphens:none;color:#c5c8c6;background-color:#27292c !important;border:#43484c;border-radius:3px}pre[class*="language-"]{padding:1em}code[class*="language-"] .token.comment,pre[class*="language-"] .token.comment,code[class*="language-"] .token.prolog,pre[class*="language-"] .token.prolog,code[class*="language-"] .token.doctype,pre[class*="language-"] .token.doctype,code[class*="language-"] .token.cdata,pre[class*="language-"] .token.cdata{color:#7C7C7C}code[class*="language-"] .token.punctuation,pre[class*="language-"] .token.punctuation{color:#96CBFE}code[class*="language-"] .namespace,pre[class*="language-"] .namespace{opacity:.7}code[class*="language-"] .token.constant,pre[class*="language-"] .token.constant{color:#99CC99}code[class*="language-"] .token.boolean,pre[class*="language-"] .token.boolean,code[class*="language-"] .token.number,pre[class*="language-"] .token.number,code[class*="language-"] .token.function-name,pre[class*="language-"] .token.function-name{color:#FF73FD}code[class*="language-"] .token.tag,pre[class*="language-"] .token.tag{color:#96CBFE}code[class*="language-"] .token.selector,pre[class*="language-"] .token.selector{color:#96CBFE}code[class*="language-"] .token.attr-name,pre[class*="language-"] .token.attr-name{color:#C6C5FE}code[class*="language-"] .token.string,pre[class*="language-"] .token.string{color:#A8FF60}code[class*="language-"] .token.char,pre[class*="language-"] .token.char{color:#FF8000}code[class*="language-"] .token.entity,pre[class*="language-"] .token.entity{color:#FFD2A7}code[class*="language-"] .token.url,pre[class*="language-"] .token.url{color:#7C7C7C}code[class*="language-"] .token.operator,pre[class*="language-"] .token.operator{color:#EDEDED}code[class*="language-"] .token.atrule,pre[class*="language-"] .token.atrule,code[class*="language-"] .token.attr-value,pre[class*="language-"] .token.attr-value,code[class*="language-"] .token.keyword,pre[class*="language-"] .token.keyword{color:#CFCB90}code[class*="language-"] .token.function,pre[class*="language-"] .token.function{color:#FFD2A7}code[class*="language-"] .token.class-name,pre[class*="language-"] .token.class-name{color:#FFD2A7}code[class*="language-"] .token.variable,pre[class*="language-"] .token.variable{color:#C6C5FE}code[class*="language-"] .token.regex,pre[class*="language-"] .token.regex,code[class*="language-"] .token.important,pre[class*="language-"] .token.important{color:#E9C062}code[class*="language-"] .token.important,pre[class*="language-"] .token.important,code[class*="language-"] .token.bold,pre[class*="language-"] .token.bold{font-weight:bold}code[class*="language-"] .token.italic,pre[class*="language-"] .token.italic{font-style:italic}code[class*="language-"] .token.entity,pre[class*="language-"] .token.entity{cursor:help}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:rgba(153,122,102,0.08);background:linear-gradient(to right, rgba(153,122,102,0.1) 70%, rgba(153,122,102,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:rgba(153,122,102,0.4);color:#f5f2f0;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px white}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview.markdown-preview {
  font-family: "Sarasa Gothic SC", sans-serif;
}
.markdown-preview.markdown-preview pre {
  font-family: "Sarasa Mono SC", sans-serif;
  max-height: calc(100vh - 250px);
}
.markdown-preview.markdown-preview pre > code {
  font-family: "Sarasa Mono SC", sans-serif;
  color: #C5C8C6;
  font-size: 1em !important;
}

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="trump-bot">Trump-bot</h1>

<p>&#x4E00;&#x4E2A;&#x6A21;&#x4EFF; Twitter &#x8D26;&#x53F7; @realDonaldTrump &#x8BED;&#x8A00;&#x98CE;&#x683C;&#x7684;&#x7B80;&#x6613; AI&#x3002;</p>
<h2 class="mume-header" id="%E7%9B%AE%E5%BD%95">&#x76EE;&#x5F55;</h2>

<ul>
<li><a href="#trump-bot">Trump-bot</a>
<ul>
<li><a href="#%E7%9B%AE%E5%BD%95">&#x76EE;&#x5F55;</a></li>
<li><a href="#%E9%80%89%E9%A2%98%E5%8A%A8%E6%9C%BA">&#x9009;&#x9898;&#x52A8;&#x673A;</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96">&#x6570;&#x636E;&#x83B7;&#x53D6;</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95">&#x6A21;&#x578B;&#x65B9;&#x6CD5;</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">&#x8BAD;&#x7EC3;&#x6A21;&#x578B;</a></li>
<li><a href="#%E7%94%9F%E6%88%90%E6%96%87%E6%9C%AC">&#x751F;&#x6210;&#x6587;&#x672C;</a></li>
<li><a href="#%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81">&#x8FD0;&#x884C;&#x4EE3;&#x7801;</a></li>
<li><a href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C">&#x5B9E;&#x9A8C;&#x7ED3;&#x679C;</a></li>
<li><a href="#%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83">&#x5B9E;&#x9A8C;&#x73AF;&#x5883;</a></li>
<li><a href="#%E7%BB%93%E8%AE%BA%E5%92%8C%E6%84%9F%E6%83%B3">&#x7ED3;&#x8BBA;&#x548C;&#x611F;&#x60F3;</a></li>
<li><a href="#%E8%B4%A1%E7%8C%AE%E8%80%85">&#x8D21;&#x732E;&#x8005;</a></li>
<li><a href="#%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE">&#x8BB8;&#x53EF;&#x534F;&#x8BAE;</a></li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="%E9%80%89%E9%A2%98%E5%8A%A8%E6%9C%BA">&#x9009;&#x9898;&#x52A8;&#x673A;</h2>

<p>&#x6587;&#x672C;&#x751F;&#x6210;&#xFF08;Text Generation&#xFF09;&#x662F;&#x81EA;&#x7136;&#x8BED;&#x8A00;&#x5904;&#x7406;&#xFF08;Natural Language Processing, NLP&#xFF09;&#x6280;&#x672F;&#x7684;&#x4E00;&#x4E2A;&#x5E38;&#x89C1;&#x7684;&#x5E94;&#x7528;&#x573A;&#x666F;&#x3002;&#x6839;&#x636E;&#x6587;&#x672C;&#x6570;&#x636E;&#x96C6;&#x7684;&#x7279;&#x5F81;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x8BAD;&#x7EC3; AI &#x751F;&#x6210;&#x6709;&#x7740;&#x7279;&#x5B9A;&#x98CE;&#x683C;&#x7684;&#x6587;&#x672C;&#x3002;&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x9009;&#x62E9;&#x4EE5;&#x7279;&#x6717;&#x666E;&#xFF08;Donald Trump&#xFF09;&#x7684;&#x63A8;&#x7279;&#xFF08;Twitter: @realDonaldTrump&#xFF09;&#x4F5C;&#x4E3A;&#x6A21;&#x4EFF;&#x5BF9;&#x8C61;&#xFF0C;&#x6709;&#x4EE5;&#x4E0B;&#x56DB;&#x70B9;&#x539F;&#x56E0;&#xFF1A;</p>
<ol>
<li>&#x7279;&#x6717;&#x666E;&#x7684;&#x63A8;&#x7279;&#x53D1;&#x9001;&#x9891;&#x7387;&#x975E;&#x5E38;&#x4E4B;&#x9AD8;&#xFF0C;&#x6709;&#x5145;&#x8DB3;&#x7684;&#x6587;&#x672C;&#x6570;&#x636E;&#x7528;&#x4E8E;&#x8BAD;&#x7EC3;</li>
<li>&#x7279;&#x6717;&#x666E;&#x7684;&#x6240;&#x6709;&#x63A8;&#x7279;&#x6570;&#x636E;&#x6709;&#x516C;&#x5F00;&#x7684;&#x83B7;&#x53D6;&#x6E20;&#x9053;&#xFF0C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4E0B;&#x8F7D;&#x4F7F;&#x7528;</li>
<li>&#x7279;&#x6717;&#x666E;&#x7684;&#x7528;&#x8BCD;&#x7B80;&#x5355;&#x76F4;&#x63A5;&#xFF0C;&#x6240;&#x4F7F;&#x7528;&#x7684;&#x8BCD;&#x6C47;&#x91CF;&#x8F83;&#x5C0F;&#xFF0C;&#x4E5F;&#x6CA1;&#x6709;&#x590D;&#x6742;&#x7684;&#x8BED;&#x6CD5;&#xFF0C;&#x4FBF;&#x4E8E;&#x8BAD;&#x7EC3;</li>
<li>&#x7279;&#x6717;&#x666E;&#x7684;&#x8BED;&#x8A00;&#x98CE;&#x683C;&#x5341;&#x5206;&#x6709;&#x8DA3;&#xFF0C;&#x5177;&#x6709;&#x4E00;&#x5B9A;&#x7684;&#x5A31;&#x4E50;&#x6027;</li>
</ol>
<p>&#x611F;&#x89C9;&#x8BAD;&#x7EC3;&#x4E00;&#x4E2A;&#x7279;&#x6717;&#x666E;&#x98CE;&#x683C;&#x7684; AI &#x4F1A;&#x6BD4;&#x8F83;&#x6709;&#x610F;&#x601D;&#xFF0C;&#x800C;&#x4E14;&#x96BE;&#x5EA6;&#x4E5F;&#x4E0D;&#x7B97;&#x5F88;&#x9AD8;&#x3002;&#x4F5C;&#x4E3A; NLP &#x521D;&#x5B66;&#x8005;&#xFF0C;&#x76EE;&#x524D;&#x8FD8;&#x4E0D;&#x662F;&#x5F88;&#x719F;&#x6089;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#xFF08;Deep Learning&#xFF09;&#xFF0C;&#x52A0;&#x4E0A;&#x671F;&#x672B;&#x5B63;&#x65F6;&#x95F4;&#x5B9E;&#x5728;&#x8FC7;&#x4E8E;&#x6709;&#x9650;&#xFF0C;&#x6700;&#x540E;&#x5C31;&#x9009;&#x62E9;&#x4E86;&#x8FD9;&#x4E2A;&#x9898;&#x76EE;&#x3002;</p>
<h2 class="mume-header" id="%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96">&#x6570;&#x636E;&#x83B7;&#x53D6;</h2>

<p>&#x5C3D;&#x7BA1;&#x7279;&#x6717;&#x666E;&#x7684;&#x63A8;&#x7279;&#x8D26;&#x53F7;&#x5728; 2021/01/08 &#x88AB;&#x6C38;&#x4E45;&#x5C01;&#x7981;&#xFF0C;&#x5E78;&#x8FD0;&#x7684;&#x662F;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x662F;&#x80FD;&#x5728;&#x7F51;&#x4E0A;&#x627E;&#x5230;&#x7279;&#x6717;&#x666E;&#x88AB;&#x5C01;&#x7981;&#x524D;&#x7684;&#x63A8;&#x7279;&#x5B58;&#x6863;&#x3002;</p>
<p>&#x5728;<a href="https://www.thetrumparchive.com">&#x8FD9;&#x91CC;</a>&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x5E74;&#x4EFD;&#x548C;&#x5173;&#x952E;&#x8BCD;&#x68C0;&#x7D22;&#x3001;&#x6D4F;&#x89C8;&#x53CA;&#x4E0B;&#x8F7D;&#x7279;&#x6717;&#x666E;&#x53D1;&#x8FC7;&#x7684;&#x6240;&#x6709;&#x63A8;&#x7279;&#x3002;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x603B;&#x5171;&#x6709;&#x5C06;&#x8FD1; 60000 &#x6761;&#x63A8;&#x7279;&#x6570;&#x636E;&#xFF0C;&#x8FD8;&#x662F;&#x76F8;&#x5F53;&#x53EF;&#x89C2;&#x7684;&#x3002;</p>
<p>&#x4F7F;&#x7528;&#x8BE5;&#x7F51;&#x7AD9;&#x63D0;&#x4F9B;&#x7684;&#x5BFC;&#x51FA;&#x529F;&#x80FD;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5F97;&#x5230; JSON &#x683C;&#x5F0F;&#x7684;&#x63A8;&#x7279;&#x6570;&#x636E;&#xFF0C;&#x4FDD;&#x5B58;&#x5728;&#x4E86; <code>data/raw_json/</code> &#x6587;&#x4EF6;&#x5939;&#x4E0B;&#x3002;&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x4EC5;&#x4E0B;&#x8F7D;&#x4E86; 2018 ~ 2021 &#x5E74;&#x7684;&#x63A8;&#x7279;&#x6570;&#x636E;&#xFF0C;&#x5E76;&#x9884;&#x5148;&#x8FC7;&#x6EE4;&#x4E86;&#x4EE5;&#x4E0B;&#x6570;&#x636E;&#xFF1A;</p>
<ol>
<li>&#x4EE5; <code>http://</code> &#x6216; <code>https://</code> &#x5F00;&#x5934;&#x7684;&#x63A8;&#x7279;&#xFF0C;&#x8FD9;&#x4E9B;&#x901A;&#x5E38;&#x662F;&#x94FE;&#x63A5;&#x5206;&#x4EAB;&#xFF0C;&#x5E76;&#x4E0D;&#x5305;&#x542B;&#x6587;&#x672C;&#x4FE1;&#x606F;</li>
<li>&#x4EE5; <code>RT</code> &#x5F00;&#x5934;&#x7684;&#x63A8;&#x7279;&#xFF0C;&#x8FD9;&#x4E9B;&#x901A;&#x5E38;&#x662F;&#x8F6C;&#x53D1;&#xFF08;retweet&#xFF09;&#x7684;&#x63A8;&#x7279;&#xFF0C;&#x4E0D;&#x662F;&#x7279;&#x6717;&#x666E;&#x672C;&#x4EBA;&#x7684;&#x53D1;&#x8A00;</li>
</ol>
<p>&#x63A5;&#x4E0B;&#x6765;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5C06;&#x8FD9;&#x4E9B; JSON &#x683C;&#x5F0F;&#x7684;&#x6570;&#x636E;&#x8FDB;&#x4E00;&#x6B65;&#x5904;&#x7406;&#xFF0C;&#x4ECE;&#x800C;&#x5F97;&#x5230;&#x4E00;&#x4E2A;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#x7684;&#x8BED;&#x6599;&#x5E93;&#x3002;&#x5728; <a href="../trump_bot/corpus.py">corpus.py</a> &#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x4E86;&#x4E24;&#x4E2A;&#x7C7B; <code>dictionary</code> &#x548C; <code>corpus</code>&#x3002;&#x5176;&#x4E2D;&#xFF0C;<code>dictionary</code> &#x7528;&#x4E8E;&#x7EF4;&#x62A4;&#x4E00;&#x4E2A;&#x8BCD;&#x5178;&#xFF0C;&#x4FDD;&#x5B58;&#x4E86;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x51FA;&#x73B0;&#x8FC7;&#x7684;&#x6240;&#x6709;&#x5355;&#x8BCD;&#xFF0C;&#x4EE5;&#x53CA;&#x76F8;&#x5E94;&#x7684;&#x7D22;&#x5F15;&#x548C;&#x51FA;&#x73B0;&#x9891;&#x7387;&#xFF1B;<code>corpus</code> &#x7528;&#x4E8E;&#x7EF4;&#x62A4;&#x4E00;&#x4E2A;&#x8BED;&#x6599;&#x5E93;&#xFF0C;&#x4EE5; <code>List[str]</code> &#x7C7B;&#x578B;&#x6309;&#x987A;&#x5E8F;&#x4FDD;&#x5B58;&#x4E86;&#x5B8C;&#x6574;&#x7684;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x5E76;&#x63D0;&#x4F9B;&#x4E86;&#x5C06; JSON &#x683C;&#x5F0F;&#x6570;&#x636E;&#x8F6C;&#x5316;&#x4E3A; text &#x683C;&#x5F0F;&#x6570;&#x636E;&#x7684;&#x5904;&#x7406;&#x65B9;&#x6CD5;&#xFF0C;&#x4EE5;&#x53CA; text &#x683C;&#x5F0F;&#x6570;&#x636E;&#x7684;&#x8BFB;&#x53D6;&#x65B9;&#x6CD5;&#x3002;</p>
<p>&#x5177;&#x4F53;&#x6765;&#x8BF4;&#xFF0C;&#x9996;&#x5148; <code>corpus</code> &#x5229;&#x7528;&#x51FD;&#x6570; <code>get_text_data</code>&#xFF0C;&#x8BFB;&#x53D6; JSON &#x683C;&#x5F0F;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x904D;&#x5386;&#x5E76;&#x63D0;&#x53D6;&#x6240;&#x6709;&#x63A8;&#x7279;&#x5BF9;&#x8C61;&#x7684; <code>text</code> &#x5B57;&#x6BB5;&#xFF08;&#x4E5F;&#x5C31;&#x662F;&#x63A8;&#x7279;&#x7684;&#x6587;&#x672C;&#x5185;&#x5BB9;&#xFF09;&#x3002;&#x7136;&#x540E;&#x6211;&#x4EEC;&#x5229;&#x7528; <a href="https://spacy.io">spaCy</a> &#x5E93;&#xFF0C;&#x5C06;&#x6BCF;&#x6761;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x5206;&#x8BCD;&#x5904;&#x7406;&#xFF0C;&#x5305;&#x62EC;&#x5C06;&#x5404;&#x79CD;&#x6807;&#x70B9;&#x7B26;&#x53F7;&#x4E0E;&#x5355;&#x8BCD;&#x5206;&#x5F00;&#xFF0C;&#x4EE5;&#x53CA;&#x5C06; <code>n&apos;t</code>, <code>&apos;s</code> &#x7B49;&#x5E38;&#x7528;&#x7F29;&#x5199;&#x4ECE;&#x5355;&#x8BCD;&#x4E0A;&#x5206;&#x79BB;&#x3002;&#x6700;&#x540E;&#x5C06;&#x5904;&#x7406;&#x540E;&#x7684;&#x6570;&#x636E;&#x4EE5; text &#x683C;&#x5F0F;&#x4FDD;&#x5B58;&#x5728; <code>data/text/</code> &#x6587;&#x4EF6;&#x5939;&#x4E0B;&#x3002;</p>
<p>&#x5F97;&#x5230; text &#x683C;&#x5F0F;&#x6570;&#x636E;&#x4EE5;&#x540E;&#xFF0C;<code>corpus</code> &#x5229;&#x7528;&#x51FD;&#x6570; <code>read_data</code> &#x5C06;&#x6570;&#x636E;&#x8F7D;&#x5165;&#x5185;&#x5B58;&#x3002;&#x4E00;&#x65B9;&#x9762;&#xFF0C;&#x5C06;&#x6BCF;&#x884C;&#x6587;&#x672C;&#x5206;&#x6210;&#x4E00;&#x7EC4;&#x5355;&#x8BCD;&#xFF0C;&#x5E76;&#x6DFB;&#x52A0;&#x53E5;&#x9996;&#x6807;&#x8BB0; <code>&lt;sos&gt;</code>&#xFF08;start of sentence&#xFF09;&#x548C;&#x53E5;&#x5C3E;&#x6807;&#x8BB0; <code>&lt;eos&gt;</code>&#xFF08;end of sentence&#xFF09;&#xFF0C;&#x5229;&#x7528;&#x51FD;&#x6570; <code>add_sentence</code> &#x4EE5; <code>List[str]</code> &#x7C7B;&#x578B;&#x4FDD;&#x5B58;&#x5728;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#xFF1B;&#x53E6;&#x4E00;&#x65B9;&#x9762;&#xFF0C;&#x5728;&#x6DFB;&#x52A0;&#x53E5;&#x5B50;&#x7684;&#x540C;&#x65F6;&#xFF0C;&#x5C06;&#x53E5;&#x5B50;&#x4E2D;&#x51FA;&#x73B0;&#x7684;&#x5355;&#x8BCD;&#x4E0D;&#x91CD;&#x590D;&#x5730;&#x4FDD;&#x5B58;&#x5230;&#x8BCD;&#x5178; <code>dictionary</code> &#x4E2D;&#xFF0C;&#x5E76;&#x8BB0;&#x5F55;&#x6B64;&#x65F6;&#x7684;&#x7D22;&#x5F15;&#xFF0C;&#x7528;&#x4E8E;&#x4E4B;&#x540E;&#x5C06;&#x53E5;&#x5B50;&#x8F6C;&#x5316;&#x4E3A;&#x5F20;&#x91CF;&#xFF08;tensor&#xFF09;&#x3002;</p>
<p>&#x5728;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x6BCF;&#x4E2A;&#x5355;&#x8BCD;&#x66FF;&#x6362;&#x4E3A;&#x5B83;&#x5728;&#x8BCD;&#x5178;&#x4E2D;&#x7684;&#x7D22;&#x5F15;&#xFF0C;&#x8FD9;&#x6837;&#x4E00;&#x4E2A;&#x53E5;&#x5B50;&#x5C31;&#x53EF;&#x4EE5;&#x8868;&#x793A;&#x4E3A;&#x4E00;&#x4E2A;&#x5F20;&#x91CF;&#x4E86;&#x3002;&#x5BF9;&#x4E8E;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x51FA;&#x73B0;&#x7684;&#x4E0D;&#x5728;&#x8BCD;&#x5178;&#x91CC;&#x7684;&#x672A;&#x77E5;&#x5355;&#x8BCD;&#xFF0C;&#x5C06;&#x4F1A;&#x88AB;&#x6807;&#x8BB0;&#x4E3A; <code>&lt;unk&gt;</code>&#xFF08;unknown&#xFF09;&#xFF0C;&#x5E76;&#x5728;&#x8F6C;&#x5316;&#x4E3A;&#x5F20;&#x91CF;&#x65F6;&#x968F;&#x673A;&#x6307;&#x6D3E;&#x4E00;&#x4E2A;&#x7D22;&#x5F15;&#x3002;</p>
<p>&#x5B8C;&#x6574;&#x4EE3;&#x7801;&#x53EF;&#x53C2;&#x89C1; <a href="../trump_bot/corpus.py">corpus.py</a>&#xFF0C;&#x5176;&#x4E2D;&#x4E3B;&#x8981;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/corpus.py</span>

<span class="token keyword">class</span> <span class="token class-name">dictionary</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    A dictionary which contains all words in the training set.
    &apos;&apos;&apos;</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Initialize the dictionary.
        &apos;&apos;&apos;</span>

        self<span class="token punctuation">.</span>idx2word<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>word2idx<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>freq_threshold <span class="token operator">=</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>start_pos <span class="token operator">=</span> <span class="token number">3</span>

        self<span class="token punctuation">.</span>unk <span class="token operator">=</span> <span class="token string">&apos;&lt;unk&gt;&apos;</span>  <span class="token comment"># unknown word</span>
        self<span class="token punctuation">.</span>eos <span class="token operator">=</span> <span class="token string">&apos;&lt;eos&gt;&apos;</span>  <span class="token comment"># end of sentence</span>
        self<span class="token punctuation">.</span>sos <span class="token operator">=</span> <span class="token string">&apos;&lt;sos&gt;&apos;</span>  <span class="token comment"># start of sentence</span>

        self<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span>self<span class="token punctuation">.</span>unk<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span>self<span class="token punctuation">.</span>eos<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sos<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">len</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Return the current size of the dictionary.
        &apos;&apos;&apos;</span>

        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx2word<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">add_word</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Add a new word to the dictionary.

        Return the index of the word.

        :param word: new word
        &apos;&apos;&apos;</span>

        <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>idx2word<span class="token punctuation">:</span>
            idx <span class="token operator">=</span> self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>idx2word<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            idx <span class="token operator">=</span> self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">return</span> idx

    <span class="token keyword">def</span> <span class="token function">clear_words</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Remove infrequent words that appears at most `freq_threshold`.
        &apos;&apos;&apos;</span>

        i<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>start_pos
        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx2word<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>freq_threshold<span class="token punctuation">:</span>
                removed_word<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>idx2word<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                self<span class="token punctuation">.</span>word2idx<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>removed_word<span class="token punctuation">)</span>

                last_word<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>idx2word<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> i <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx2word<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token keyword">break</span>

                <span class="token comment"># Swap the removed word with the last word in dictionary</span>
                self<span class="token punctuation">.</span>idx2word<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> last_word
                self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>idx2freq<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>word2idx<span class="token punctuation">[</span>last_word<span class="token punctuation">]</span> <span class="token operator">=</span> i
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                i <span class="token operator">+=</span> <span class="token number">1</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/corpus.py</span>

<span class="token keyword">class</span> <span class="token class-name">corpus</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    A corpus built with the training set.
    &apos;&apos;&apos;</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Initialize the corpus.
        &apos;&apos;&apos;</span>

        self<span class="token punctuation">.</span>json_dir<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>realpath<span class="token punctuation">(</span><span class="token string">&apos;data/raw_json&apos;</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>text_dir<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>realpath<span class="token punctuation">(</span><span class="token string">&apos;data/text&apos;</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>data_file <span class="token operator">=</span> <span class="token string">&apos;data.txt&apos;</span>

        self<span class="token punctuation">.</span>train_set<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>train_proportion <span class="token operator">=</span> <span class="token number">0.4</span>

        self<span class="token punctuation">.</span>dev_set<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>dev_proportion <span class="token operator">=</span> <span class="token number">0.4</span>

        self<span class="token punctuation">.</span>test_set<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>test_proportion <span class="token operator">=</span> <span class="token number">0.2</span>

        self<span class="token punctuation">.</span>dictionary <span class="token operator">=</span> dictionary<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_text_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> all_in_one<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Parse a dataset from JSON to plain text.

        :param file_name: file name of the dataset without extension
        :param all_in_one: write to a single file
        &apos;&apos;&apos;</span>

        <span class="token keyword">def</span> <span class="token function">_filter_text</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">&apos;&apos;&apos;
            Filter a line of text and replace certain words.

            Return the filtered text.

            :param text: input text
            &apos;&apos;&apos;</span>

            <span class="token keyword">return</span> <span class="token punctuation">(</span>
                text
                <span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">&apos;&amp;amp;&apos;</span><span class="token punctuation">,</span> <span class="token string">&apos;&amp;&apos;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">&apos;&amp;amp,&apos;</span><span class="token punctuation">,</span> <span class="token string">&apos;&amp;&apos;</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>

        json_path<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>json_dir<span class="token punctuation">,</span> file_name <span class="token operator">+</span> <span class="token string">&apos;.json&apos;</span><span class="token punctuation">)</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>json_path<span class="token punctuation">,</span> <span class="token string">&apos;r&apos;</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">&apos;utf-8&apos;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fi<span class="token punctuation">:</span>
                data<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span> <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>fi<span class="token punctuation">)</span>
        <span class="token keyword">except</span> FileNotFoundError<span class="token punctuation">:</span>
            data<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        text_name<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>data_file <span class="token keyword">if</span> all_in_one <span class="token keyword">else</span> file_name <span class="token operator">+</span> <span class="token string">&apos;.txt&apos;</span>
        text_path<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>text_dir<span class="token punctuation">,</span> text_name<span class="token punctuation">)</span>
        buffer_size <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">20</span>  <span class="token comment"># 1 MB</span>
        tokenizer <span class="token operator">=</span> get_tokenizer<span class="token punctuation">(</span><span class="token string">&apos;spacy&apos;</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>text_path<span class="token punctuation">,</span> <span class="token string">&apos;a&apos;</span> <span class="token keyword">if</span> all_in_one <span class="token keyword">else</span> <span class="token string">&apos;w&apos;</span><span class="token punctuation">,</span> buffering<span class="token operator">=</span>buffer_size<span class="token punctuation">)</span> <span class="token keyword">as</span> fo<span class="token punctuation">:</span>
            <span class="token builtin">buffer</span><span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&apos;&apos;</span>
            <span class="token comment"># Reverse the list to sort by time in ascending order</span>
            <span class="token keyword">for</span> entry <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
                t<span class="token punctuation">:</span> tweet <span class="token operator">=</span> decode_tweet<span class="token punctuation">(</span>entry<span class="token punctuation">)</span>
                text<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> _filter_text<span class="token punctuation">(</span>unidecode<span class="token punctuation">(</span>t<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>
                words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
                <span class="token builtin">buffer</span> <span class="token operator">+=</span> <span class="token string">&apos; &apos;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&apos;\n&apos;</span>
            fo<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_all_text_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> all_in_one<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Parse all datasets in `json_dir` from JSON to plain text.

        :param all_in_one: write to a single file
        &apos;&apos;&apos;</span>

        <span class="token keyword">if</span> all_in_one<span class="token punctuation">:</span>
            <span class="token comment"># Clear the content</span>
            text_path<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>text_dir<span class="token punctuation">,</span> self<span class="token punctuation">.</span>data_file<span class="token punctuation">)</span>
            <span class="token builtin">open</span><span class="token punctuation">(</span>text_path<span class="token punctuation">,</span> <span class="token string">&apos;w&apos;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> json_entry <span class="token keyword">in</span> os<span class="token punctuation">.</span>scandir<span class="token punctuation">(</span>self<span class="token punctuation">.</span>json_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
            file_name<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> json_entry<span class="token punctuation">.</span>name
            <span class="token keyword">if</span> file_name<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">&apos;.json&apos;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>get_text_data<span class="token punctuation">(</span>file_name<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token string">&apos;.json&apos;</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> all_in_one<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">add_sentence</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dataset<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&apos;train&apos;</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Add a new sentence to the corpus.

        :param words: a preprocessed word list of the new sentence
        :param dataset: which dataset, can be `&apos;train&apos;`, `&apos;dev&apos;` or `&apos;test&apos;`
        &apos;&apos;&apos;</span>

        <span class="token keyword">if</span> <span class="token keyword">not</span> words<span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> words<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">&apos;...&apos;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                words<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                words<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>dictionary<span class="token punctuation">.</span>sos<span class="token punctuation">)</span>
            <span class="token keyword">if</span> words<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">&apos;...&apos;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                words<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dictionary<span class="token punctuation">.</span>eos<span class="token punctuation">)</span>
        <span class="token keyword">except</span> IndexError<span class="token punctuation">:</span>
            <span class="token keyword">pass</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>dictionary<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
            <span class="token keyword">if</span> dataset <span class="token operator">==</span> <span class="token string">&apos;dev&apos;</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>dev_set <span class="token operator">+=</span> words
            <span class="token keyword">elif</span> dataset <span class="token operator">==</span> <span class="token string">&apos;test&apos;</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>test_set <span class="token operator">+=</span> words
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>train_set <span class="token operator">+=</span> words

    <span class="token keyword">def</span> <span class="token function">read_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Read a dataset from a file, and append to the corpus.

        :param file_name: file name of the dataset without extension
        &apos;&apos;&apos;</span>

        text_name<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> file_name <span class="token operator">+</span> <span class="token string">&apos;.txt&apos;</span> <span class="token keyword">if</span> file_name <span class="token keyword">else</span> self<span class="token punctuation">.</span>data_file
        text_path<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>text_dir<span class="token punctuation">,</span> text_name<span class="token punctuation">)</span>

        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>text_path<span class="token punctuation">,</span> <span class="token string">&apos;r&apos;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fi<span class="token punctuation">:</span>
            all_lines<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> fi<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> floor<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>all_lines<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>train_proportion<span class="token punctuation">)</span>
            dev_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> floor<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>all_lines<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>dev_proportion<span class="token punctuation">)</span>

            <span class="token keyword">for</span> line <span class="token keyword">in</span> all_lines<span class="token punctuation">[</span><span class="token punctuation">:</span>train_size<span class="token punctuation">]</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>add_sentence<span class="token punctuation">(</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&apos;train&apos;</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> all_lines<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">]</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>add_sentence<span class="token punctuation">(</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&apos;dev&apos;</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> all_lines<span class="token punctuation">[</span>train_size<span class="token operator">+</span>dev_size<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>add_sentence<span class="token punctuation">(</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&apos;test&apos;</span><span class="token punctuation">)</span>

            <span class="token comment"># self.dictionary.clear_words()</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><h2 class="mume-header" id="%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95">&#x6A21;&#x578B;&#x65B9;&#x6CD5;</h2>

<p>&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x4E3B;&#x8981;&#x91C7;&#x7528; GRU&#xFF08;Gate Recurrent Unit&#xFF09;&#x6A21;&#x578B;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#xFF0C;&#x5B83;&#x662F;&#x5FAA;&#x73AF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF08;Recurrent Neural Network, RNN&#xFF09;&#x7684;&#x4E00;&#x79CD;&#x3002;</p>
<p><img src="../assets/gru.png" alt="GRU"></p>
<p>&#x4E3A;&#x4EC0;&#x4E48;&#x91C7;&#x7528; GRU&#xFF1F;&#x9996;&#x5148;&#x662F;&#x56E0;&#x4E3A;&#x7EAF; RNN &#x5B58;&#x5728;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#xFF08;Gradient Vanishing&#xFF09;&#x7684;&#x95EE;&#x9898;&#x3002;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x968F;&#x7740;&#x8BAD;&#x7EC3;&#x7684;&#x6DF1;&#x5165;&#xFF0C;&#x5F53; RNN &#x5904;&#x7406;&#x540E;&#x671F;&#x7684;&#x6570;&#x636E;&#x65F6;&#xFF0C;&#x524D;&#x671F;&#x7684;&#x6570;&#x636E;&#x7531;&#x4E8E;&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;&#x4F1A;&#x4E0D;&#x65AD;&#x4E58;&#x4E00;&#x4E9B;&#x5C0F;&#x4E8E; 1 &#x7684;&#x6570;&#xFF0C;&#x5BFC;&#x81F4;&#x540E;&#x671F;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#xFF08;&#x5F52;&#x96F6;&#xFF09;&#xFF0C;&#x4E0D;&#x518D;&#x53C2;&#x4E0E;&#x5B66;&#x4E60;&#xFF0C;&#x8FD9;&#x4E9B;&#x524D;&#x671F;&#x6570;&#x636E;&#x5C31;&#x76F8;&#x5F53;&#x4E8E;&#x662F;&#x88AB;&#x300C;&#x9057;&#x5FD8;&#x300D;&#x4E86;&#x3002;&#x8FD9;&#x6837;&#x7684;&#x7ED3;&#x679C;&#x662F; RNN &#x53EA;&#x5177;&#x5907;&#x77ED;&#x671F;&#x8BB0;&#x5FC6;&#xFF0C;&#x800C;&#x5BF9;&#x4E8E;&#x6587;&#x672C;&#x751F;&#x6210;&#x8FD9;&#x6837;&#x7684;&#x4EFB;&#x52A1;&#x6765;&#x8BF4;&#xFF0C;&#x8FD9;&#x5C06;&#x5BFC;&#x81F4; RNN &#x5F88;&#x96BE;&#x6709;&#x4E0A;&#x4E0B;&#x6587;&#x7684;&#x6982;&#x5FF5;&#xFF0C;&#x56E0;&#x6B64;&#x751F;&#x6210;&#x7684;&#x6587;&#x672C;&#x53EF;&#x80FD;&#x4ECE;&#x5F00;&#x59CB;&#x5230;&#x7ED3;&#x675F;&#x5C31;&#x6362;&#x4E86;&#x597D;&#x51E0;&#x4E2A;&#x4E3B;&#x9898;&#x3002;&#x800C; LSTM&#xFF08;Long Short-Term Memory&#xFF09;&#x548C; GRU &#x5219;&#x89E3;&#x51B3;&#x4E86;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x3002;&#x90A3;&#x4E3A;&#x4EC0;&#x4E48;&#x4E0D;&#x91C7;&#x7528; LSTM &#x5462;&#xFF1F;&#x8FD9;&#x662F;&#x56E0;&#x4E3A; GRU &#x76F8;&#x8F83;&#x4E8E; LSTM &#x8BAD;&#x7EC3;&#x901F;&#x5EA6;&#x66F4;&#x5FEB;&#xFF0C;&#x540C;&#x7B49;&#x60C5;&#x51B5;&#x4E0B;&#x9700;&#x8981;&#x7684;&#x8BAD;&#x7EC3;&#x65F6;&#x95F4;&#x66F4;&#x77ED;&#xFF0C;&#x800C;&#x4E14;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#x4E5F;&#x76F8;&#x5BF9;&#x7B80;&#x6D01;&#xFF08;&#x56E0;&#x4E3A;&#x6A21;&#x578B;&#x7B80;&#x5355;&#xFF09;&#x3002;&#x7531;&#x4E8E;&#x671F;&#x672B;&#x5B63;&#x65F6;&#x95F4;&#x8F83;&#x5C11;&#xFF0C;&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x5C31;&#x9009;&#x62E9;&#x4E86; GRU &#x6A21;&#x578B;&#x3002;</p>
<p>&#x66F4;&#x5177;&#x4F53;&#x5730;&#xFF0C;&#x5BF9;&#x4E8E;&#x6BCF;&#x4E00;&#x4E2A;&#x795E;&#x7ECF;&#x5143;&#xFF1A;</p>
<ol>
<li>&#x8F93;&#x5165; input &#x5148;&#x7ECF;&#x8FC7;&#x4E00;&#x5C42; <a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html">Embedding</a>&#xFF0C;&#x5B83;&#x7684;&#x4F5C;&#x7528;&#x662F;&#x5C06;&#x6211;&#x4EEC;&#x7684;&#x8F93;&#x5165;&#x8BCD;&#xFF08;&#x6240;&#x5BF9;&#x5E94;&#x7684;&#x5F20;&#x91CF;&#xFF0C;&#x53D6;&#x51B3;&#x4E8E;&#x5B83;&#x5728;&#x8BCD;&#x5178;&#x4E2D;&#x7684;&#x7D22;&#x5F15;&#xFF09;&#x8F6C;&#x5316;&#x4E3A;&#x4E00;&#x4E2A;&#x8BCD;&#x5411;&#x91CF;&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x4E00;&#x4E2A;&#x7F16;&#x7801;&#x5668;&#xFF1B;</li>
<li>Embedding &#x540E;&#x7684; input &#x518D;&#x7ECF;&#x8FC7;&#x4E00;&#x5C42; <a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html">Dropout</a>&#xFF0C;&#x5B83;&#x7684;&#x4F5C;&#x7528;&#x662F;&#x968F;&#x673A;&#x5C4F;&#x853D;&#x4E00;&#x90E8;&#x5206;&#x8F93;&#x5165;&#xFF0C;&#x4EE5;&#x5C3D;&#x91CF;&#x6291;&#x5236;&#x8FC7;&#x62DF;&#x5408;&#x73B0;&#x8C61;&#xFF0C;&#x51CF;&#x5C0F;&#x8BAD;&#x7EC3;&#x635F;&#x5931;&#xFF08;Training loss&#xFF09;&#x548C;&#x9A8C;&#x8BC1;&#x635F;&#x5931;&#xFF08;Validation loss&#xFF09;&#x95F4;&#x7684;&#x5DEE;&#x8DDD;&#xFF1B;</li>
<li>Dropout &#x540E;&#x7684; input &#x548C;&#x4E0A;&#x4E00;&#x5C42;&#x7684; hidden state &#x4E00;&#x8D77;&#x4F20;&#x5165; <a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html">GRU</a>&#xFF0C;&#x8BA1;&#x7B97;&#x5F97;&#x5230;&#x8F93;&#x51FA; output &#x548C;&#x66F4;&#x65B0;&#x540E;&#x7684; hidden state&#xFF1B;</li>
<li>&#x8F93;&#x51FA; output &#x518D;&#x7ECF;&#x8FC7;&#x4E00;&#x5C42; Dropout&#xFF0C;&#x4F5C;&#x7528;&#x540C; 2.&#xFF1B;</li>
<li>Dropout &#x540E;&#x7684; output &#x6700;&#x540E;&#x7ECF;&#x8FC7;&#x4E00;&#x5C42; <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">Linear</a>&#xFF0C;&#x5B83;&#x7684;&#x4F5C;&#x7528;&#x662F;&#x5C06;&#x6211;&#x4EEC;&#x7684;&#x8F93;&#x51FA;&#x8BCD;&#x5411;&#x91CF;&#x8FD8;&#x539F;&#x4E3A;&#x76F8;&#x5E94;&#x7684;&#x8F93;&#x51FA;&#x8BCD;&#xFF08;&#x6240;&#x5BF9;&#x5E94;&#x7684;&#x5F20;&#x91CF;&#xFF09;&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x4E00;&#x4E2A;&#x89E3;&#x7801;&#x5668;&#x3002;</li>
</ol>
<p>&#x6A21;&#x578B;&#x5229;&#x7528; <a href="https://pytorch.org">PyTorch</a> &#x6846;&#x67B6;&#x5EFA;&#x7ACB;&#xFF0C;&#x5B8C;&#x6574;&#x4EE3;&#x7801;&#x53EF;&#x53C2;&#x89C1; <a href="../trump_bot/model.py">model.py</a>&#xFF0C;&#x5176;&#x4E2D;&#x4E3B;&#x8981;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/model.py</span>

<span class="token keyword">class</span> <span class="token class-name">rnn</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    Build an RNN model.

    This model will take the last character as input and is expected to output
    the next character. There are three layers - one linear layer that encodes
    the input character into an internal state, one GRU layer (which may itself
    have multiple layers) that operates on that internal state and a hidden
    state, and a decoder layer that outputs the probability distribution.
    &apos;&apos;&apos;</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> hidden_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> output_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 num_layers<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> dropout<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Initialize the RNN model.

        :param input_size: the number of expected features in the input
        :param hidden_size: the number of features in the hidden state
        :param output_size: the number of expected features in the output
        :param num_layers: the number of recurrent layers
        &apos;&apos;&apos;</span>

        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers

        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span>
                          num_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inp<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> hid<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tuple<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        The forward function which defines the network structure.

        Return the result of output tensor and hidden tensor.

        :param inp: input tensor
        :param hid: hidden tensor
        &apos;&apos;&apos;</span>

        emb <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>inp<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        emb <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
        out<span class="token punctuation">,</span> hid <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>emb<span class="token punctuation">,</span> hid<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        dec <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> dec<span class="token punctuation">,</span> hid

    <span class="token keyword">def</span> <span class="token function">init_hidden</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&apos;&apos;&apos;
        Initialize the hidden state.

        :param batch_size: batch size
        &apos;&apos;&apos;</span>

        weight <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> weight<span class="token punctuation">.</span>new_zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><h2 class="mume-header" id="%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">&#x8BAD;&#x7EC3;&#x6A21;&#x578B;</h2>

<p>&#x6574;&#x4F53;&#x7684;&#x8BAD;&#x7EC3;&#x601D;&#x8DEF;&#x662F;&#xFF0C;&#x6BCF;&#x6B21;&#x4ECE;&#x8BAD;&#x7EC3;&#x96C6;&#x4E2D;&#x968F;&#x673A;&#x62BD;&#x53D6;&#x4E00;&#x4E2A;&#x56FA;&#x5B9A;&#x957F;&#x5EA6;&#x7684;&#x7247;&#x6BB5; <span class="mathjax-exps">$\text {words}$</span>&#xFF0C;&#x4E0D;&#x59A8;&#x8BBE;&#x603B;&#x5171;&#x6709; <span class="mathjax-exps">$n$</span> &#x4E2A;&#x8BCD;&#xFF0C;&#x5C06; <span class="mathjax-exps">$\text {words}$</span> &#x4E2D;&#x524D; <span class="mathjax-exps">$n - 1$</span> &#x4E2A;&#x8BCD;&#x4F5C;&#x4E3A;&#x8F93;&#x5165; <span class="mathjax-exps">$\text {inputs}$</span>&#xFF0C;&#x540E; <span class="mathjax-exps">$n - 1$</span> &#x4E2A;&#x8BCD;&#x4F5C;&#x4E3A;&#x76EE;&#x6807; <span class="mathjax-exps">$\text {targets}$</span>&#x3002;&#x904D;&#x5386; <span class="mathjax-exps">$\text {inputs}$</span>&#xFF0C;&#x6A21;&#x578B;&#x6839;&#x636E;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x8BCD; <span class="mathjax-exps">$\text {inputs}[i]$</span> &#x548C;&#x5F53;&#x524D;&#x7684; hidden state &#x9884;&#x6D4B;&#x4E00;&#x4E2A;&#x8F93;&#x51FA;&#x8BCD; <span class="mathjax-exps">$\text {outputs}[i]$</span> &#x4F5C;&#x4E3A; <span class="mathjax-exps">$\text {inputs}[i]$</span> &#x53EF;&#x80FD;&#x7684;&#x540E;&#x7EE7;&#x8BCD;&#x3002;&#x7136;&#x540E;&#x5C06;&#x8F93;&#x51FA;&#x8BCD; <span class="mathjax-exps">$\text {outputs}[i]$</span> &#x548C;&#x76EE;&#x6807;&#x8BCD; <span class="mathjax-exps">$\text {targets}[i]$</span> &#x8FDB;&#x884C;&#x6BD4;&#x5BF9;&#xFF0C;&#x4F7F;&#x7528;&#x4EA4;&#x53C9;&#x71B5;&#xFF08;cross entropy&#xFF09;&#x8BA1;&#x7B97;&#x635F;&#x5931;&#xFF08;loss&#xFF09;&#x51FD;&#x6570;&#xFF0C;&#x5E76;&#x5229;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x5C1D;&#x8BD5;&#x964D;&#x4F4E;&#x635F;&#x5931;&#x3002;&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x4F7F;&#x7528; <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam">Adam</a> &#x7B97;&#x6CD5;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#xFF0C;&#x5B83;&#x53EF;&#x4EE5;&#x81EA;&#x9002;&#x5E94;&#x5730;&#x8C03;&#x8282;&#x5B66;&#x4E60;&#x7387;&#xFF08;Learning rate&#xFF09;&#x3002;</p>
<p>&#x5177;&#x4F53;&#x4EE3;&#x7801;&#x53EF;&#x53C2;&#x89C1; <a href="../trump_bot/main.py">main.py</a> &#x7684; <code>train_model</code> &#x51FD;&#x6570;&#xFF0C;&#x5176;&#x4E2D;&#x4E3B;&#x8981;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tuple<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    The main training function.

    Return all training losses and all validation losses.
    &apos;&apos;&apos;</span>

    all_train_losses<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    all_valid_losses<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    total_train_loss<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.0</span>
    total_valid_loss<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.0</span>
    min_valid_loss<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">4.0</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_loss<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> train<span class="token punctuation">(</span><span class="token operator">*</span>get_random_pair<span class="token punctuation">(</span><span class="token string">&apos;train&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        valid_loss<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> validate<span class="token punctuation">(</span><span class="token operator">*</span>get_random_pair<span class="token punctuation">(</span><span class="token string">&apos;dev&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        total_train_loss <span class="token operator">+=</span> train_loss
        total_valid_loss <span class="token operator">+=</span> valid_loss

        <span class="token keyword">if</span> valid_loss <span class="token operator">&lt;</span> min_valid_loss<span class="token punctuation">:</span>
            save_model<span class="token punctuation">(</span>valid_loss<span class="token punctuation">)</span>
            min_valid_loss <span class="token operator">=</span> valid_loss

        <span class="token keyword">if</span> epoch <span class="token operator">%</span> print_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            progress<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> epoch <span class="token operator">/</span> num_epochs <span class="token operator">*</span> <span class="token number">100</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>
                <span class="token string">&apos;{}: ({} {:.1f}%) train_loss: {:.3f}, valid_loss: {:.3f}&apos;</span>
                <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                    duration_since<span class="token punctuation">(</span>start_time<span class="token punctuation">)</span><span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> progress<span class="token punctuation">,</span>
                    train_loss<span class="token punctuation">,</span> valid_loss<span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            evaluate_model<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> epoch <span class="token operator">%</span> plot_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            all_train_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>total_train_loss <span class="token operator">/</span> plot_every<span class="token punctuation">)</span>
            all_valid_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>total_valid_loss <span class="token operator">/</span> plot_every<span class="token punctuation">)</span>
            total_train_loss <span class="token operator">=</span> <span class="token number">0.0</span>
            total_valid_loss <span class="token operator">=</span> <span class="token number">0.0</span>

    <span class="token keyword">return</span> all_train_losses<span class="token punctuation">,</span> all_valid_losses
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">get_random_pair</span><span class="token punctuation">(</span>dataset<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&apos;train&apos;</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tuple<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    Return a random pair of input and target from the dataset.

    :param dataset: which dataset, can be `&apos;train&apos;`, `&apos;dev&apos;` or `&apos;test&apos;`
    &apos;&apos;&apos;</span>

    <span class="token keyword">if</span> dataset <span class="token operator">==</span> <span class="token string">&apos;dev&apos;</span><span class="token punctuation">:</span>
        src <span class="token operator">=</span> cp<span class="token punctuation">.</span>dev_set
    <span class="token keyword">elif</span> dataset <span class="token operator">==</span> <span class="token string">&apos;test&apos;</span><span class="token punctuation">:</span>
        src <span class="token operator">=</span> cp<span class="token punctuation">.</span>test_set
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        src <span class="token operator">=</span> cp<span class="token punctuation">.</span>train_set

    max_i<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>src<span class="token punctuation">)</span> <span class="token operator">-</span> chunk_size
    i<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> max_i<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    inp_words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> src<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>chunk_size<span class="token punctuation">]</span>
    inp<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> words_to_tensor<span class="token punctuation">(</span>inp_words<span class="token punctuation">)</span>

    tar_words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> src<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token operator">+</span>chunk_size<span class="token punctuation">]</span>
    tar<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> words_to_tensor<span class="token punctuation">(</span>tar_words<span class="token punctuation">)</span>

    <span class="token keyword">return</span> inp<span class="token punctuation">,</span> tar
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>inp<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> tar<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    Train the model using a pair of input and target.

    Return the loss.

    :param inp: input tensor
    :param tar: target tensor
    &apos;&apos;&apos;</span>

    m<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    m<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    hid<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> m<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>inp<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        out<span class="token punctuation">,</span> hid <span class="token operator">=</span> m<span class="token punctuation">(</span>inp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hid<span class="token punctuation">)</span>
        loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> tar<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> clip<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> chunk_size
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">validate</span><span class="token punctuation">(</span>inp<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> tar<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    Validate the model using a pair of input and target.

    Return the loss.

    :param inp: input tensor
    :param tar: target tensor
    &apos;&apos;&apos;</span>

    m<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    hid<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> m<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>inp<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            out<span class="token punctuation">,</span> hid <span class="token operator">=</span> m<span class="token punctuation">(</span>inp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hid<span class="token punctuation">)</span>
            loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> tar<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> chunk_size
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><h2 class="mume-header" id="%E7%94%9F%E6%88%90%E6%96%87%E6%9C%AC">&#x751F;&#x6210;&#x6587;&#x672C;</h2>

<p>&#x751F;&#x6210;&#x6587;&#x672C;&#x7684;&#x65B9;&#x5F0F;&#x662F;&#xFF0C;&#x5148;&#x4ECE;&#x6D4B;&#x8BD5;&#x96C6;&#x4E2D;&#x968F;&#x673A;&#x9009;&#x53D6;&#x82E5;&#x5E72;&#x4E2A;&#xFF08;&#x53C2;&#x6570;&#x53EF;&#x8C03;&#x8282;&#xFF09;&#x8FDE;&#x7EED;&#x5355;&#x8BCD;&#xFF0C;&#x7136;&#x540E;&#x4EE5;&#x8FD9;&#x51E0;&#x4E2A;&#x5355;&#x8BCD;&#x4E3A;&#x5F00;&#x5934;&#xFF0C;&#x5229;&#x7528;&#x6A21;&#x578B;&#x4E00;&#x4E2A;&#x4E00;&#x4E2A;&#x9884;&#x6D4B;&#x63A5;&#x4E0B;&#x6765;&#x7684;&#x5355;&#x8BCD;&#xFF0C;&#x4ECE;&#x800C;&#x7EC4;&#x6210;&#x4E00;&#x4E2A;&#x53E5;&#x5B50;&#x3002;</p>
<p>&#x5177;&#x4F53;&#x4EE3;&#x7801;&#x53EF;&#x53C2;&#x89C1; <a href="../trump_bot/main.py">main.py</a> &#x7684; <code>generate</code> &#x51FD;&#x6570;&#xFF0C;&#x5176;&#x4E2D;&#x4E3B;&#x8981;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    Generate new sentences using the best model, and save to local file.
    &apos;&apos;&apos;</span>

    load_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> batch_size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        progress<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> i <span class="token operator">/</span> batch_size <span class="token operator">*</span> <span class="token number">100</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&apos;(</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>progress<span class="token punctuation">:</span><span class="token format-spec">.1f</span><span class="token punctuation">}</span></span><span class="token string">%)&apos;</span></span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">&apos;\r&apos;</span><span class="token punctuation">,</span> flush<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        evaluate_model<span class="token punctuation">(</span>save<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>save<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    The main evaluating function.

    :param save: save the output to local file
    &apos;&apos;&apos;</span>

    m<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    prime_words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> get_random_words<span class="token punctuation">(</span>prime_len<span class="token punctuation">,</span> <span class="token string">&apos;dev&apos;</span><span class="token punctuation">)</span>
    predicted_words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>
        prime_words<span class="token punctuation">,</span> predict_len<span class="token punctuation">,</span> temperature<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    output<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos; &apos;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>predicted_words<span class="token punctuation">)</span>
    <span class="token keyword">if</span> save<span class="token punctuation">:</span>
        current_time<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&apos;%Y-%m-%d %H:%M:%S&apos;</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>output_path<span class="token punctuation">,</span> <span class="token string">&apos;a&apos;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&apos;</span><span class="token interpolation"><span class="token punctuation">{</span>current_time<span class="token punctuation">}</span></span><span class="token string">:\n</span><span class="token interpolation"><span class="token punctuation">{</span>output<span class="token punctuation">}</span></span><span class="token string">\n\n&apos;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">get_random_words</span><span class="token punctuation">(</span>count<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> dataset<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&apos;dev&apos;</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    Return a sequence of random words from the dataset.

    :param count: how many words are required
    :param dataset: which dataset, can be `&apos;train&apos;`, `&apos;dev&apos;` or `&apos;test&apos;`
    &apos;&apos;&apos;</span>

    <span class="token keyword">if</span> dataset <span class="token operator">==</span> <span class="token string">&apos;dev&apos;</span><span class="token punctuation">:</span>
        src <span class="token operator">=</span> cp<span class="token punctuation">.</span>dev_set
    <span class="token keyword">elif</span> dataset <span class="token operator">==</span> <span class="token string">&apos;test&apos;</span><span class="token punctuation">:</span>
        src <span class="token operator">=</span> cp<span class="token punctuation">.</span>test_set
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        src <span class="token operator">=</span> cp<span class="token punctuation">.</span>train_set

    max_i<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>src<span class="token punctuation">)</span> <span class="token operator">-</span> count
    i<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> max_i<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> src<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>count<span class="token punctuation">]</span>

    <span class="token keyword">return</span> words
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="python {.line-numbers}" class="language-python line-numbers"><span class="token comment"># trump_bot/main.py</span>

<span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>prime_words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> predict_len<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">,</span>
             temperature<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.8</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    Evaluate the network by generating a sentence using a priming word.

    To evaluate the network we feed one word at a time, use the outputs of the
    network as a probability distribution for the next word, and repeat.
    To start generation we pass some priming words to start setting up the
    hidden state, from which we then generate one word at a time.

    Return the predicted words.

    :param prime_words: priming words to start
    :param predict_len: expected length of words to predict
    :param temperature: randomness of predictions; higher value results in more diversity
    &apos;&apos;&apos;</span>

    hid<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> m<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> prime_words<span class="token punctuation">:</span>
        prime_words <span class="token operator">=</span> <span class="token punctuation">[</span>cp<span class="token punctuation">.</span>dictionary<span class="token punctuation">.</span>sos<span class="token punctuation">]</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        prime_inp<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> words_to_tensor<span class="token punctuation">(</span>prime_words<span class="token punctuation">)</span>
        predicted_words<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> prime_words

        <span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>prime_words<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            _<span class="token punctuation">,</span> hid <span class="token operator">=</span> m<span class="token punctuation">(</span>prime_inp<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">,</span> hid<span class="token punctuation">)</span>
        inp<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> prime_inp<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

        <span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>predict_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            out<span class="token punctuation">,</span> hid <span class="token operator">=</span> m<span class="token punctuation">(</span>inp<span class="token punctuation">,</span> hid<span class="token punctuation">)</span>

            <span class="token comment"># Sample from the network as a multinomial distribution</span>
            out_dist<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>div<span class="token punctuation">(</span>temperature<span class="token punctuation">)</span><span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span>
            top_i<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>out_dist<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

            <span class="token comment"># Add predicted word to words and use as next input</span>
            predicted_word<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> cp<span class="token punctuation">.</span>dictionary<span class="token punctuation">.</span>idx2word<span class="token punctuation">[</span>top_i<span class="token punctuation">]</span>
            predicted_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>predicted_word<span class="token punctuation">)</span>
            <span class="token comment"># if (predicted_word == cp.dictionary.eos):</span>
            <span class="token comment">#     break</span>

            inp<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>top_i<span class="token punctuation">)</span>

    <span class="token keyword">return</span> predicted_words
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><h2 class="mume-header" id="%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81">&#x8FD0;&#x884C;&#x4EE3;&#x7801;</h2>

<p>&#x914D;&#x7F6E;&#x73AF;&#x5883;&#x524D;&#xFF0C;&#x9996;&#x5148;&#x9700;&#x8981;&#x5B89;&#x88C5;&#x4EE5;&#x4E0B;&#x4F9D;&#x8D56;&#xFF1A;</p>
<ul>
<li><a href="https://www.anaconda.com/products/individual">Anaconda</a> 4.9 &#x6216;&#x4EE5;&#x4E0A;&#xFF08;&#x542B; Python 3.8&#xFF09;</li>
<li><a href="https://developer.nvidia.com/cuda-10.1-download-archive-base">CUDA</a> 10.1</li>
</ul>
<p>&#x7136;&#x540E;&#x521B;&#x5EFA;&#x5E76;&#x542F;&#x52A8; conda &#x865A;&#x62DF;&#x73AF;&#x5883;&#xFF0C;&#x540C;&#x65F6;&#x5B89;&#x88C5;&#x6240;&#x6709;&#x4F9D;&#x8D56;&#x5305;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="bash {.line-numbers}" class="language-bash line-numbers">conda <span class="token function">env</span> update --name trump_bot --file environment.yml
conda activate trump_bot
python -m spacy download en_core_web_sm
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></pre><p>&#x6700;&#x540E;&#x6267;&#x884C;&#x4E3B;&#x7A0B;&#x5E8F;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x5F00;&#x59CB;&#x8BAD;&#x7EC3;&#x4E86;&#x3002;</p>
<pre data-role="codeBlock" data-info="bash {.line-numbers}" class="language-bash line-numbers">python ./trump_bot/main.py
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></pre><p>&#x76EE;&#x524D;&#x6682;&#x65F6;&#x4E0D;&#x652F;&#x6301;&#x4F20;&#x9012;&#x53C2;&#x6570;&#xFF0C;&#x56E0;&#x6B64;&#x9700;&#x8981;&#x624B;&#x52A8;&#x5728; <a href="../trump_bot/main.py">main.py</a> &#x91CC;&#x8C03;&#x6574;&#x3002;</p>
<p>&#x4F7F;&#x7528;&#x6D4B;&#x8BD5;&#x96C6;&#x751F;&#x6210;&#x7684;&#x6587;&#x672C;&#x4F4D;&#x4E8E; <code>output/output.txt</code>&#xFF0C;&#x6A21;&#x578B;&#x5B66;&#x4E60;&#x7387;&#x7684;&#x66F2;&#x7EBF;&#x56FE;&#x4F4D;&#x4E8E; <code>assets/loss.png</code>&#x3002;</p>
<h2 class="mume-header" id="%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C">&#x5B9E;&#x9A8C;&#x7ED3;&#x679C;</h2>

<p>&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;&#x7684;&#x8BAD;&#x7EC3;&#x635F;&#x5931;&#x548C;&#x9A8C;&#x8BC1;&#x635F;&#x5931;&#x5982;&#x56FE;&#x6240;&#x793A;&#xFF08;&#x4F7F;&#x7528; <a href="../trump_bot/main.py">main.py</a> &#x4E2D;&#x5B9A;&#x4E49;&#x7684;&#x9ED8;&#x8BA4;&#x53C2;&#x6570;&#xFF09;&#xFF1A;</p>
<p><img src="../assets/loss.png" alt="&#x5B66;&#x4E60;&#x66F2;&#x7EBF;"></p>
<p>&#x4E00;&#x4E9B;&#x751F;&#x6210;&#x6587;&#x672C;&#x5C55;&#x793A;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="text {.line-numbers}" class="language-text line-numbers"><code># 2021-01-18 23:50:37

I did a big book to be great President: Emergency (Fake.
</code><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="text {.line-numbers}" class="language-text line-numbers"><code># 2021-01-18 23:50:38

The Democrats have been done to all of the President. Great Complete!
Enjoy of Border: New House States in a GREAT!
China Virus, and all, including almost 2020, and have been the Impeachment Hoax!
</code><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="text {.line-numbers}" class="language-text line-numbers"><code># 2021-01-19 00:57:52

this is a fraud on the World of the Fake News Media for me, on the Border (and keep was the Fake News Media, would keep win to the Republican side, and over the negative of the State of the National Left
do n&apos;t believe the Trump Report
There all over the President of the Federal Government so I know, the Democrats are doing a great job to do.
Our lowest success of the United States and that will be doing quickly on the Mueller Report, that is doing a good job you need, the USA will be doing a great job!
The GREAT Media is working more to U.S., or any of the highly Left can never let a short of our Country.
</code><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="text {.line-numbers}" class="language-text line-numbers"><code># 2021-01-19 00:57:53

There is no crime of our Country. They are doing the Do Nothing Democrats, and that, the Democrats, are doing a great job, and even the Democrats, or to the Democrats!
Sleepy n&apos;t want to report the Trump Administration
The Fake News Media is not better, but the Trump News, and it is a great job!
The Democrats are great with the Democrats that the Democrats are with the Republican Party.
</code><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="text {.line-numbers}" class="language-text line-numbers"><code># 2021-01-19 00:57:54

Biggest part of the National Administration is being built with the same side to use the Fake News Media, are doing more than ever before!
I will be watching from the Great State of the Russia Virus, has in the White House to the Republican side of the United States now.
</code><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></pre><pre data-role="codeBlock" data-info="text {.line-numbers}" class="language-text line-numbers"><code># 2021-01-19 00:57:55

Democrat run cities and states are doing their job with respect that I am pleased to announce the Democrats in the Republican Party.
Chinese are very adept at to the White House!
I have n&apos;t think the Federal Party are doing such being important in their stone to do of the President and the State of the DNC in the history of the United States, China and keep more than he. Great!
</code><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></pre><p>&#x7ECF;&#x68C0;&#x9A8C;&#xFF0C;&#x8FD9;&#x4E9B;&#x5E76;&#x4E0D;&#x662F;&#x7279;&#x6717;&#x666E;&#x7684;&#x539F;&#x8BDD;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#x786E;&#x5B9E;&#x662F; AI &#x81EA;&#x5DF1;&#x751F;&#x6210;&#x7684;&#x6587;&#x672C;&#x3002;</p>
<h2 class="mume-header" id="%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83">&#x5B9E;&#x9A8C;&#x73AF;&#x5883;</h2>

<ul>
<li>OS: Ubuntu Server 20.04.1 LTS (GNU/Linux 5.4.0-62-generic x86_64)</li>
<li>GPU: NVIDIA Tesla V100-NVLINK-32G &#xD7; 1
<ul>
<li>CUDA: 10.1.105</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="%E7%BB%93%E8%AE%BA%E5%92%8C%E6%84%9F%E6%83%B3">&#x7ED3;&#x8BBA;&#x548C;&#x611F;&#x60F3;</h2>

<p>&#x76EE;&#x524D;&#x4ECE;&#x751F;&#x6210;&#x7684;&#x6587;&#x672C;&#x6765;&#x770B;&#xFF0C;&#x6548;&#x679C;&#x8FD8;&#x7B97;&#x53EF;&#x4EE5;&#x3002;&#x6574;&#x4E2A;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x8FD8;&#x662F;&#x6BD4;&#x8F83;&#x6709;&#x8DA3;&#x7684;&#xFF0C;&#x4E2D;&#x95F4;&#x751F;&#x6210;&#x4E86;&#x8BB8;&#x591A;&#x5341;&#x5206;&#x6709;&#x7279;&#x6717;&#x666E;&#x98CE;&#x683C;&#x7684;&#x641E;&#x7B11;&#x53E5;&#x5B50;&#x3002;&#x524D;&#x671F;&#x8BAD;&#x7EC3;&#x4E00;&#x76F4;&#x5728;&#x7528;&#x81EA;&#x5DF1;&#x7B14;&#x8BB0;&#x672C;&#x7684; 1050 Ti &#x8DD1;&#xFF0C;&#x663E;&#x5B58;&#x5B8C;&#x5168;&#x4E0D;&#x591F;&#xFF0C;&#x8DD1;&#x4E00;&#x8F6E;&#x7684;&#x901F;&#x5EA6;&#x4E5F;&#x975E;&#x5E38;&#x6162;&#x3002;&#x540E;&#x6765;&#x770B;&#x65F6;&#x95F4;&#x6765;&#x4E0D;&#x53CA;&#x4E86;&#xFF0C;&#x5B9E;&#x5728;&#x53D7;&#x4E0D;&#x4E86;&#x8FD8;&#x662F;&#x53BB;&#x79DF;&#x4E86;&#x53F0; GPU &#x670D;&#x52A1;&#x5668;&#x3002;&#x540E;&#x6765;&#x5C31;&#x4E00;&#x76F4;&#x7528;&#x7684; Tesla V100 &#x8DD1;&#xFF0C;&#x8212;&#x670D;&#x591A;&#x4E86;&#x3002;</p>
<p>&#x4E0D;&#x8FC7;&#x8C03;&#x53C2;&#x7684;&#x8FC7;&#x7A0B;&#x771F;&#x5C31;&#x70BC;&#x4E39;&#xFF0C;&#x5176;&#x5B9E;&#x5230;&#x6700;&#x540E;&#x4E5F;&#x6CA1;&#x80FD;&#x8C03;&#x51FA;&#x4E00;&#x4E2A;&#x975E;&#x5E38;&#x597D;&#x770B;&#x7684;&#x5B66;&#x4E60;&#x66F2;&#x7EBF;&#xFF08;Learning curve&#xFF09;&#xFF0C;&#x6BD5;&#x7ADF;&#x5BF9;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x8FD8;&#x662F;&#x6CA1;&#x4EC0;&#x4E48;&#x7ECF;&#x9A8C;&#x3002;&#x671F;&#x672B;&#x5B63;&#x4E5F;&#x5B9E;&#x5728;&#x62BD;&#x4E0D;&#x51FA;&#x65F6;&#x95F4;&#xFF0C;&#x4ECE;&#x521A;&#x5F00;&#x59CB; RNN&#x3001;PyTorch &#x4E4B;&#x7C7B;&#x7684;&#x4EC0;&#x4E48;&#x90FD;&#x4E0D;&#x4F1A;&#x5230;&#x51E0;&#x5929;&#x5185;&#x80FD;&#x505A;&#x51FA;&#x4E00;&#x4E2A;&#x6210;&#x54C1;&#xFF0C;&#x5DF2;&#x7ECF;&#x4E0D;&#x5BB9;&#x6613;&#x4E86;&#x3002;&#x4ECE; 12 &#x6708;&#x4E2D;&#x65EC;&#x4E00;&#x76F4;&#x6301;&#x7EED;&#x6BCF;&#x5929;&#x5DE5;&#x4F5C; 12 &#x5C0F;&#x65F6;&#x5DE6;&#x53F3;&#x76F4;&#x5230; 1 &#x6708;&#x4E0B;&#x65EC;&#x5C31;&#x6CA1;&#x6B47;&#x8FC7;&#xFF0C;&#x906D;&#x4E0D;&#x4F4F;&#x3002;</p>
<h2 class="mume-header" id="%E8%B4%A1%E7%8C%AE%E8%80%85">&#x8D21;&#x732E;&#x8005;</h2>

<ul>
<li><a href="https://github.com/hakula139"><strong>Hakula Chen</strong></a>&lt;<a href="mailto:i@hakula.xyz">i@hakula.xyz</a>&gt; - &#x590D;&#x65E6;&#x5927;&#x5B66;</li>
</ul>
<h2 class="mume-header" id="%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE">&#x8BB8;&#x53EF;&#x534F;&#x8BAE;</h2>

<p>&#x672C;&#x9879;&#x76EE;&#x9075;&#x5FAA; GNU General Public License v3.0 &#x8BB8;&#x53EF;&#x534F;&#x8BAE;&#xFF0C;&#x8BE6;&#x60C5;&#x53C2;&#x89C1; <a href="../LICENSE">LICENSE</a> &#x6587;&#x4EF6;&#x3002;</p>

      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>